{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CNN imports\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Naive Bayes models\n",
    "import sklearn.naive_bayes as nb\n",
    "\n",
    "# ensemble Decision Trees\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Boosting methods\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to quickly call the accuracy of the model\n",
    "def model_acc(model):\n",
    "    print(f'training score: {round(model.score(X_train,y_train) * 100, 4)}%')\n",
    "    print(f'testing score: {round(model.score(X_test,y_test) * 100, 4)}%')\n",
    "    \n",
    "# function that formats the predictions of the CNN into a 0-1 binary\n",
    "def predictions(cnn, x):\n",
    "    preds = cnn.predict_on_batch(x)\n",
    "    return preds > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "train = pd.read_csv(\"../Data/Train & Test/eq_tweets_train.csv\")\n",
    "test = pd.read_csv(\"../Data/Train & Test/eq_tweets_test.csv\")\n",
    "\n",
    "# creating variables to fit the model\n",
    "X_train = train[\"tweet_text\"]\n",
    "y_train = train[\"label\"]\n",
    "X_test = test[\"tweet_text\"]\n",
    "y_test = test[\"relevant\"]\n",
    "\n",
    "# fitting the TFiDF for the below models\n",
    "tvec = TfidfVectorizer(max_features=5000, \n",
    "                       ngram_range=(1,2), \n",
    "                       stop_words=\"english\")\n",
    "tvec.fit(X_train)\n",
    "\n",
    "# resetting the x variables to be the correctly formatted matrix\n",
    "X_train = tvec.transform(X_train).todense()\n",
    "X_test = tvec.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Score\n",
    "________________________\n",
    "\n",
    "### 50% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "___________________\n",
    "### Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15162/15162 [==============================] - 67s 4ms/sample - loss: 0.1455 - acc: 0.9457\n",
      "Epoch 2/5\n",
      "15162/15162 [==============================] - 66s 4ms/sample - loss: 0.0652 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "15162/15162 [==============================] - 66s 4ms/sample - loss: 0.0305 - acc: 0.9885\n",
      "Epoch 4/5\n",
      "15162/15162 [==============================] - 66s 4ms/sample - loss: 0.0186 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "15162/15162 [==============================] - 66s 4ms/sample - loss: 0.0131 - acc: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20241faa2e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instatiate the model with adding the layers and nodes\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 1000,\n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'relu',\n",
    "                     input_dim=5000)\n",
    "              )\n",
    "\n",
    "classifier.add(Dense(units = 1000,\n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'relu'\n",
    "                    )\n",
    "              )\n",
    "\n",
    "classifier.add(Dense(units = 1,\n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'sigmoid'\n",
    "                    )\n",
    "              )\n",
    "\n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss = 'binary_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "# fit the model with train\n",
    "classifier.fit(X_train, \n",
    "               y_train, \n",
    "               batch_size = 10, \n",
    "               epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.6175%\n",
      "testing score: 97.7119%\n"
     ]
    }
   ],
   "source": [
    "# finding the accuracy of the model\n",
    "y_hat_train = predictions(classifier, X_train)\n",
    "y_hat_test = predictions(classifier, X_test)\n",
    "\n",
    "print(f'training score: {round(accuracy_score(y_train, y_hat_train) * 100, 4)}%')\n",
    "print(f'testing score: {round(accuracy_score(y_test, y_hat_test) * 100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 96.4451%\n",
      "testing score: 97.9661%\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "logr = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "model_acc(logr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 95.0402%\n",
      "testing score: 97.3729%\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "# instantiate the model\n",
    "mnnb = nb.MultinomialNB()\n",
    "\n",
    "# fit the model\n",
    "mnnb.fit(X_train, y_train)\n",
    "\n",
    "model_acc(mnnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 93.8596%\n",
      "testing score: 93.8983%\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# instantiate the model\n",
    "gaus = nb.GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "gaus.fit(X_train, y_train)\n",
    "\n",
    "model_acc(gaus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.9275%\n",
      "testing score: 98.5593%\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "rfclass = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fit the model\n",
    "rfclass.fit(X_train, y_train)\n",
    "\n",
    "model_acc(rfclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.9275%\n",
      "testing score: 97.8814%\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model\n",
    "etclass = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "# fit the model\n",
    "etclass.fit(X_train, y_train)\n",
    "\n",
    "model_acc(etclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instatiate the model\n",
    "# svc = SVC(kernel=\"rbf\", gamma=\"scale\")\n",
    "\n",
    "# # fit the model\n",
    "# svc.fit(X_train, y_train)\n",
    "\n",
    "# model_acc(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "_____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 95.2579%\n",
      "testing score: 98.8136%\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model\n",
    "ada_boost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# fit the model\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "model_acc(ada_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 94.7039%\n",
      "testing score: 98.8983%\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model\n",
    "gradient_boost = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# fit the model\n",
    "gradient_boost.fit(X_train, y_train)\n",
    "\n",
    "model_acc(gradient_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rfclass, open('rndm_forest.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.9275%\n",
      "testing score: 98.5593%\n"
     ]
    }
   ],
   "source": [
    "# testing the save and if it works\n",
    "load = pickle.load(open('rndm_forest.sav', 'rb'))\n",
    "model_acc(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tvec, open('tvec.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
